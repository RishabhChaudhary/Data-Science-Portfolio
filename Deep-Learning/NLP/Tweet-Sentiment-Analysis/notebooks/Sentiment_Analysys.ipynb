{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis\n",
    "\n",
    "### Problem Statement\n",
    "- We have dataset of tweets from various users. We need to classify the tweets as positive(0) or negative(1) based on the sentiment.\n",
    "\n",
    "### Dataset\n",
    "- The dataset is taken from kaggle. The link to the dataset is given below.\n",
    "- https://www.kaggle.com/kazanova/sentiment140\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "SEED = 42\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/train_2kmZucJ.csv\")\n",
    "df_test = pd.read_csv(\"../input/test_12QyDcx.csv\")\n",
    "df_sub = pd.read_csv(\"../input/sample_submission_LnhVWA4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      1   \n",
       "\n",
       "                                                                                                                                 tweet  \n",
       "0     #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone  \n",
       "1  Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/  \n",
       "2          We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu  \n",
       "3                     I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/  \n",
       "4         What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>I hate the new #iphone upgrade. Won't let me download apps. #ugh #apple sucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7922</td>\n",
       "      <td>currently shitting my fucking pants. #apple #iMac #cashmoney #raddest #swagswagswag http://instagr.am/p/UUIS0bIBZo/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7923</td>\n",
       "      <td>I'd like to puts some CD-ROMS on my iPad, is that possible?' — Yes, but wouldn't that block the screen?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7924</td>\n",
       "      <td>My ipod is officially dead. I lost all my pictures and videos from the 1D and 5sos concert,and from Vet Camp #hatinglife #sobbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7925</td>\n",
       "      <td>Been fighting iTunes all night! I only want the music I $&amp;@*# paid for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  \\\n",
       "0  7921   \n",
       "1  7922   \n",
       "2  7923   \n",
       "3  7924   \n",
       "4  7925   \n",
       "\n",
       "                                                                                                                               tweet  \n",
       "0                                                      I hate the new #iphone upgrade. Won't let me download apps. #ugh #apple sucks  \n",
       "1                currently shitting my fucking pants. #apple #iMac #cashmoney #raddest #swagswagswag http://instagr.am/p/UUIS0bIBZo/  \n",
       "2                          I'd like to puts some CD-ROMS on my iPad, is that possible?' — Yes, but wouldn't that block the screen?\\n  \n",
       "3  My ipod is officially dead. I lost all my pictures and videos from the 1D and 5sos concert,and from Vet Camp #hatinglife #sobbing  \n",
       "4                                                             Been fighting iTunes all night! I only want the music I $&@*# paid for  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  label\n",
       "0  7921      0\n",
       "1  7922      0\n",
       "2  7923      0\n",
       "3  7924      0\n",
       "4  7925      0"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a utility function to time the execution of a function\n",
    "def time_it(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text).get_text()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    # Subsitute \"$&@*#\" with word \"curseword\"\n",
    "    curseword = re.compile(r'[$&@*#]{2,}')\n",
    "    text = curseword.sub(\"curseword\", text)\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19026/3841407435.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text).get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 1.2144443988800049 seconds\n"
     ]
    }
   ],
   "source": [
    "@time_it\n",
    "def clean(df):\n",
    "    df[\"clean_tweet\"] = df[\"tweet\"].apply(clean_text)\n",
    "    return df\n",
    "\n",
    "df_train = clean(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone</td>\n",
       "      <td>fingerprint  pregnancy test    android  apps  beautiful  cute  health  igers  iphoneonly  iphonesia  iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/</td>\n",
       "      <td>finally a transparant silicon case    thanks to my uncle     yay  sony  xperia  s  sonyexperias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu</td>\n",
       "      <td>we love this  would you go   talk  makememories  unplug  relax  iphone  smartphone  wifi  connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/</td>\n",
       "      <td>i m wired i know i m george i was made that way     iphone  cute  daventry  home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!</td>\n",
       "      <td>what amazing service  apple won t even talk to me about a question i have unless i pay them        for their stupid support</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      1   \n",
       "\n",
       "                                                                                                                                 tweet  \\\n",
       "0     #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone   \n",
       "1  Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/   \n",
       "2          We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu   \n",
       "3                     I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/   \n",
       "4         What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!   \n",
       "\n",
       "                                                                                                                    clean_tweet  \n",
       "0                   fingerprint  pregnancy test    android  apps  beautiful  cute  health  igers  iphoneonly  iphonesia  iphone  \n",
       "1                            finally a transparant silicon case    thanks to my uncle     yay  sony  xperia  s  sonyexperias     \n",
       "2                        we love this  would you go   talk  makememories  unplug  relax  iphone  smartphone  wifi  connect       \n",
       "3                                            i m wired i know i m george i was made that way     iphone  cute  daventry  home    \n",
       "4  what amazing service  apple won t even talk to me about a question i have unless i pay them        for their stupid support   "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19026/3841407435.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text).get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.3080263137817383 seconds\n"
     ]
    }
   ],
   "source": [
    "df_test = clean(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>I hate the new #iphone upgrade. Won't let me download apps. #ugh #apple sucks</td>\n",
       "      <td>i hate the new  iphone upgrade  won t let me download apps   ugh  apple sucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7922</td>\n",
       "      <td>currently shitting my fucking pants. #apple #iMac #cashmoney #raddest #swagswagswag http://instagr.am/p/UUIS0bIBZo/</td>\n",
       "      <td>currently shitting my fucking pants   apple  imac  cashmoney  raddest  swagswagswag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7923</td>\n",
       "      <td>I'd like to puts some CD-ROMS on my iPad, is that possible?' — Yes, but wouldn't that block the screen?\\n</td>\n",
       "      <td>i d like to puts some cd roms on my ipad  is that possible     yes  but wouldn t that block the screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7924</td>\n",
       "      <td>My ipod is officially dead. I lost all my pictures and videos from the 1D and 5sos concert,and from Vet Camp #hatinglife #sobbing</td>\n",
       "      <td>my ipod is officially dead  i lost all my pictures and videos from the  d and  sos concert and from vet camp  hatinglife  sobbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7925</td>\n",
       "      <td>Been fighting iTunes all night! I only want the music I $&amp;@*# paid for</td>\n",
       "      <td>been fighting itunes all night  i only want the music i curseword paid for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  \\\n",
       "0  7921   \n",
       "1  7922   \n",
       "2  7923   \n",
       "3  7924   \n",
       "4  7925   \n",
       "\n",
       "                                                                                                                               tweet  \\\n",
       "0                                                      I hate the new #iphone upgrade. Won't let me download apps. #ugh #apple sucks   \n",
       "1                currently shitting my fucking pants. #apple #iMac #cashmoney #raddest #swagswagswag http://instagr.am/p/UUIS0bIBZo/   \n",
       "2                          I'd like to puts some CD-ROMS on my iPad, is that possible?' — Yes, but wouldn't that block the screen?\\n   \n",
       "3  My ipod is officially dead. I lost all my pictures and videos from the 1D and 5sos concert,and from Vet Camp #hatinglife #sobbing   \n",
       "4                                                             Been fighting iTunes all night! I only want the music I $&@*# paid for   \n",
       "\n",
       "                                                                                                                         clean_tweet  \n",
       "0                                                      i hate the new  iphone upgrade  won t let me download apps   ugh  apple sucks  \n",
       "1                                              currently shitting my fucking pants   apple  imac  cashmoney  raddest  swagswagswag    \n",
       "2                           i d like to puts some cd roms on my ipad  is that possible     yes  but wouldn t that block the screen    \n",
       "3  my ipod is officially dead  i lost all my pictures and videos from the  d and  sos concert and from vet camp  hatinglife  sobbing  \n",
       "4                                                         been fighting itunes all night  i only want the music i curseword paid for  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' fingerprint  pregnancy test    android  apps  beautiful  cute  health  igers  iphoneonly  iphonesia  iphone'"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"clean_tweet\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variable\n",
    "X = df_train[\"clean_tweet\"]\n",
    "y = df_train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#prepare a tokenizer\n",
    "x_tokenizer = Tokenizer() \n",
    "\n",
    "x_tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iphone': 1,\n",
       " 'apple': 2,\n",
       " 'i': 3,\n",
       " 'my': 4,\n",
       " 'the': 5,\n",
       " 'to': 6,\n",
       " 'a': 7,\n",
       " 'samsung': 8,\n",
       " 'and': 9,\n",
       " 'it': 10,\n",
       " 'new': 11,\n",
       " 's': 12,\n",
       " 'for': 13,\n",
       " 'twitter': 14,\n",
       " 'com': 15,\n",
       " 'me': 16,\n",
       " 'you': 17,\n",
       " 'phone': 18,\n",
       " 'is': 19,\n",
       " 'sony': 20,\n",
       " 'follow': 21,\n",
       " 'on': 22,\n",
       " 'in': 23,\n",
       " 'of': 24,\n",
       " 'this': 25,\n",
       " 't': 26,\n",
       " 'pic': 27,\n",
       " 'with': 28,\n",
       " 'ipad': 29,\n",
       " 'like': 30,\n",
       " 'so': 31,\n",
       " 'have': 32,\n",
       " 'just': 33,\n",
       " 'at': 34,\n",
       " 'life': 35,\n",
       " 'android': 36,\n",
       " 'ios': 37,\n",
       " 'love': 38,\n",
       " 'your': 39,\n",
       " 'now': 40,\n",
       " 'rt': 41,\n",
       " 'that': 42,\n",
       " 'day': 43,\n",
       " 'all': 44,\n",
       " 'can': 45,\n",
       " 'instagram': 46,\n",
       " 'curseword': 47,\n",
       " 'an': 48,\n",
       " 'cute': 49,\n",
       " 'photo': 50,\n",
       " 'today': 51,\n",
       " 'm': 52,\n",
       " 'gain': 53,\n",
       " 'not': 54,\n",
       " 'photography': 55,\n",
       " 'get': 56,\n",
       " 'galaxy': 57,\n",
       " 'back': 58,\n",
       " 'got': 59,\n",
       " 'from': 60,\n",
       " 'fun': 61,\n",
       " 'be': 62,\n",
       " 'case': 63,\n",
       " 'news': 64,\n",
       " 'app': 65,\n",
       " 'out': 66,\n",
       " 'music': 67,\n",
       " 'instagood': 68,\n",
       " 'happy': 69,\n",
       " 'who': 70,\n",
       " 'time': 71,\n",
       " 'no': 72,\n",
       " 'funny': 73,\n",
       " 'lol': 74,\n",
       " 'fashion': 75,\n",
       " 'beautiful': 76,\n",
       " 'birthday': 77,\n",
       " 'are': 78,\n",
       " 'but': 79,\n",
       " 'if': 80,\n",
       " 'smile': 81,\n",
       " 'itunes': 82,\n",
       " 'one': 83,\n",
       " 'work': 84,\n",
       " 'up': 85,\n",
       " 'ipod': 86,\n",
       " 'iphonex': 87,\n",
       " 'tech': 88,\n",
       " 'd': 89,\n",
       " 'when': 90,\n",
       " 'photooftheday': 91,\n",
       " 'we': 92,\n",
       " 'everyone': 93,\n",
       " 'why': 94,\n",
       " 'finally': 95,\n",
       " 'good': 96,\n",
       " 'ps': 97,\n",
       " 'what': 98,\n",
       " 'apps': 99,\n",
       " 'how': 100,\n",
       " 'more': 101,\n",
       " 'girl': 102,\n",
       " 'will': 103,\n",
       " 'mac': 104,\n",
       " 'must': 105,\n",
       " 'update': 106,\n",
       " 'note': 107,\n",
       " 'sougofollow': 108,\n",
       " 'make': 109,\n",
       " 'followers': 110,\n",
       " 'they': 111,\n",
       " 'amazing': 112,\n",
       " 'as': 113,\n",
       " 'selfie': 114,\n",
       " 'about': 115,\n",
       " 'do': 116,\n",
       " 'fuck': 117,\n",
       " 'fail': 118,\n",
       " 'rts': 119,\n",
       " 'igers': 120,\n",
       " 'thanks': 121,\n",
       " 'friends': 122,\n",
       " 'home': 123,\n",
       " 'off': 124,\n",
       " 'by': 125,\n",
       " 'cool': 126,\n",
       " 'iphonesia': 127,\n",
       " 'don': 128,\n",
       " 'or': 129,\n",
       " 'was': 130,\n",
       " 'want': 131,\n",
       " 'free': 132,\n",
       " 'has': 133,\n",
       " 'would': 134,\n",
       " 'family': 135,\n",
       " 'baby': 136,\n",
       " 'best': 137,\n",
       " 'u': 138,\n",
       " 'hate': 139,\n",
       " 'camera': 140,\n",
       " 'am': 141,\n",
       " 'art': 142,\n",
       " 'go': 143,\n",
       " 'iphoneonly': 144,\n",
       " 'had': 145,\n",
       " 'gift': 146,\n",
       " 'smartphone': 147,\n",
       " 'christmas': 148,\n",
       " 'health': 149,\n",
       " 'x': 150,\n",
       " 'every': 151,\n",
       " 'here': 152,\n",
       " 'only': 153,\n",
       " 'live': 154,\n",
       " 'white': 155,\n",
       " 'game': 156,\n",
       " 'sale': 157,\n",
       " 'picoftheday': 158,\n",
       " 'fucking': 159,\n",
       " 've': 160,\n",
       " 'money': 161,\n",
       " 'much': 162,\n",
       " 'summer': 163,\n",
       " 'nature': 164,\n",
       " 'look': 165,\n",
       " 'still': 166,\n",
       " 'games': 167,\n",
       " 'mobile': 168,\n",
       " 'plus': 169,\n",
       " 'awesome': 170,\n",
       " 'screen': 171,\n",
       " 'macbook': 172,\n",
       " 'motorola': 173,\n",
       " 'its': 174,\n",
       " 'thank': 175,\n",
       " 'g': 176,\n",
       " 'need': 177,\n",
       " 'windows': 178,\n",
       " 'great': 179,\n",
       " 'laptop': 180,\n",
       " 'charger': 181,\n",
       " 'instamood': 182,\n",
       " 'been': 183,\n",
       " 'sexy': 184,\n",
       " 'night': 185,\n",
       " 'know': 186,\n",
       " 'followme': 187,\n",
       " 'there': 188,\n",
       " 'nice': 189,\n",
       " 'because': 190,\n",
       " 'our': 191,\n",
       " 'black': 192,\n",
       " 'ever': 193,\n",
       " 'even': 194,\n",
       " 'buy': 195,\n",
       " 'beauty': 196,\n",
       " 'year': 197,\n",
       " 'gb': 198,\n",
       " 'going': 199,\n",
       " 'after': 200,\n",
       " 'over': 201,\n",
       " 'again': 202,\n",
       " 'excited': 203,\n",
       " 'wish': 204,\n",
       " 'pink': 205,\n",
       " 'ff': 206,\n",
       " 'use': 207,\n",
       " 'than': 208,\n",
       " 'style': 209,\n",
       " 'old': 210,\n",
       " 'suck': 211,\n",
       " 'f': 212,\n",
       " 'colors': 213,\n",
       " 'b': 214,\n",
       " 'technology': 215,\n",
       " 'tv': 216,\n",
       " 'last': 217,\n",
       " 'never': 218,\n",
       " 'morning': 219,\n",
       " 'first': 220,\n",
       " 'then': 221,\n",
       " 'sweet': 222,\n",
       " 'thing': 223,\n",
       " 'them': 224,\n",
       " 'right': 225,\n",
       " 'store': 226,\n",
       " 'too': 227,\n",
       " 'people': 228,\n",
       " 'really': 229,\n",
       " 'download': 230,\n",
       " 'everything': 231,\n",
       " 'cases': 232,\n",
       " 'shopping': 233,\n",
       " 'hey': 234,\n",
       " 'retweet': 235,\n",
       " 'accessories': 236,\n",
       " 'playstation': 237,\n",
       " 'their': 238,\n",
       " 'red': 239,\n",
       " 'photos': 240,\n",
       " 'nokia': 241,\n",
       " 'well': 242,\n",
       " 'w': 243,\n",
       " 'k': 244,\n",
       " 'instadaily': 245,\n",
       " 'minute': 246,\n",
       " 'world': 247,\n",
       " 'ig': 248,\n",
       " 'google': 249,\n",
       " 'yay': 250,\n",
       " 'another': 251,\n",
       " 'us': 252,\n",
       " 'gaming': 253,\n",
       " 'via': 254,\n",
       " 'travel': 255,\n",
       " 'pretty': 256,\n",
       " 'galaxys': 257,\n",
       " 'fuckyou': 258,\n",
       " 'boy': 259,\n",
       " 'working': 260,\n",
       " 'computer': 261,\n",
       " 'some': 262,\n",
       " 'food': 263,\n",
       " 'made': 264,\n",
       " 'l': 265,\n",
       " 'won': 266,\n",
       " 'stupid': 267,\n",
       " 'present': 268,\n",
       " 'watch': 269,\n",
       " 'cover': 270,\n",
       " 'products': 271,\n",
       " 'any': 272,\n",
       " 'happiness': 273,\n",
       " 'appstore': 274,\n",
       " 'sun': 275,\n",
       " 'e': 276,\n",
       " 'hours': 277,\n",
       " 'check': 278,\n",
       " 'think': 279,\n",
       " 'always': 280,\n",
       " 'does': 281,\n",
       " 'blue': 282,\n",
       " 'see': 283,\n",
       " 'battery': 284,\n",
       " 'phones': 285,\n",
       " 'getting': 286,\n",
       " 'sunday': 287,\n",
       " 'sunset': 288,\n",
       " 'friday': 289,\n",
       " 'customer': 290,\n",
       " 'green': 291,\n",
       " 'amazon': 292,\n",
       " 'p': 293,\n",
       " 'blackberry': 294,\n",
       " 'say': 295,\n",
       " 're': 296,\n",
       " 'weekend': 297,\n",
       " 'c': 298,\n",
       " 'laugh': 299,\n",
       " 'count': 300,\n",
       " 'take': 301,\n",
       " 'week': 302,\n",
       " 'capetown': 303,\n",
       " 'guys': 304,\n",
       " 'doesn': 305,\n",
       " 'bought': 306,\n",
       " 'video': 307,\n",
       " 'headphones': 308,\n",
       " 'since': 309,\n",
       " 'tweegram': 310,\n",
       " 'macbookpro': 311,\n",
       " 'girls': 312,\n",
       " 'book': 313,\n",
       " 'gold': 314,\n",
       " 'keep': 315,\n",
       " 'xperia': 316,\n",
       " 'tls': 317,\n",
       " 'o': 318,\n",
       " 'facebook': 319,\n",
       " 'y': 320,\n",
       " 'design': 321,\n",
       " 'days': 322,\n",
       " 'hello': 323,\n",
       " 'sky': 324,\n",
       " 'trying': 325,\n",
       " 'instapic': 326,\n",
       " 'myself': 327,\n",
       " 'r': 328,\n",
       " 'hard': 329,\n",
       " 'wow': 330,\n",
       " 'other': 331,\n",
       " 'surf': 332,\n",
       " 'top': 333,\n",
       " 'll': 334,\n",
       " 'big': 335,\n",
       " 'let': 336,\n",
       " 'youtube': 337,\n",
       " 'iphoneography': 338,\n",
       " 'twitch': 339,\n",
       " 'wait': 340,\n",
       " 'friend': 341,\n",
       " 'n': 342,\n",
       " 'th': 343,\n",
       " 'oneplus': 344,\n",
       " 'hot': 345,\n",
       " 'capetownsup': 346,\n",
       " 'sup': 347,\n",
       " 'offers': 348,\n",
       " 'doing': 349,\n",
       " 'ya': 350,\n",
       " 'oh': 351,\n",
       " 'come': 352,\n",
       " 'put': 353,\n",
       " 'did': 354,\n",
       " 'man': 355,\n",
       " 'down': 356,\n",
       " 'tablet': 357,\n",
       " 'better': 358,\n",
       " 'god': 359,\n",
       " 'find': 360,\n",
       " 'dog': 361,\n",
       " 'little': 362,\n",
       " 'pro': 363,\n",
       " 'siri': 364,\n",
       " 'beach': 365,\n",
       " 'im': 366,\n",
       " 'two': 367,\n",
       " 'party': 368,\n",
       " 'share': 369,\n",
       " 'play': 370,\n",
       " 'newyear': 371,\n",
       " 'wifi': 372,\n",
       " 'hateapple': 373,\n",
       " 'way': 374,\n",
       " 'fix': 375,\n",
       " 'deals': 376,\n",
       " 'lost': 377,\n",
       " 'cat': 378,\n",
       " 'gamer': 379,\n",
       " 'dear': 380,\n",
       " 'upgrade': 381,\n",
       " 'he': 382,\n",
       " 'these': 383,\n",
       " 'should': 384,\n",
       " 'power': 385,\n",
       " 'mine': 386,\n",
       " 'valentine': 387,\n",
       " 'years': 388,\n",
       " 'z': 389,\n",
       " 'try': 390,\n",
       " 'kids': 391,\n",
       " 'followback': 392,\n",
       " 'picture': 393,\n",
       " 'please': 394,\n",
       " 'give': 395,\n",
       " 'face': 396,\n",
       " 'insta': 397,\n",
       " 'crazy': 398,\n",
       " 'pictures': 399,\n",
       " 'hair': 400,\n",
       " 'yeah': 401,\n",
       " 'using': 402,\n",
       " 'yes': 403,\n",
       " 'j': 404,\n",
       " 'very': 405,\n",
       " 'usa': 406,\n",
       " 'product': 407,\n",
       " 'dating': 408,\n",
       " 'available': 409,\n",
       " 'shop': 410,\n",
       " 'microsoft': 411,\n",
       " 'coming': 412,\n",
       " 'service': 413,\n",
       " 'took': 414,\n",
       " 'heart': 415,\n",
       " 'jobs': 416,\n",
       " 'having': 417,\n",
       " 'could': 418,\n",
       " 'her': 419,\n",
       " 'text': 420,\n",
       " 'vsco': 421,\n",
       " 'miss': 422,\n",
       " 'welcome': 423,\n",
       " 'sucks': 424,\n",
       " 'deleted': 425,\n",
       " 'bestprice': 426,\n",
       " 'gonna': 427,\n",
       " 'updated': 428,\n",
       " 'came': 429,\n",
       " 'hour': 430,\n",
       " 'sales': 431,\n",
       " 'help': 432,\n",
       " 'nofilter': 433,\n",
       " 'tbt': 434,\n",
       " 'mini': 435,\n",
       " 'seriously': 436,\n",
       " 'newphone': 437,\n",
       " 'may': 438,\n",
       " 'q': 439,\n",
       " 'already': 440,\n",
       " 'switch': 441,\n",
       " 'couple': 442,\n",
       " 'most': 443,\n",
       " 'soon': 444,\n",
       " 'random': 445,\n",
       " 'blog': 446,\n",
       " 'toys': 447,\n",
       " 'enjoy': 448,\n",
       " 'done': 449,\n",
       " 'into': 450,\n",
       " 'gifts': 451,\n",
       " 'didn': 452,\n",
       " 'makes': 453,\n",
       " 'discount': 454,\n",
       " 'waiting': 455,\n",
       " 'support': 456,\n",
       " 'trip': 457,\n",
       " 'job': 458,\n",
       " 'verizon': 459,\n",
       " 'holiday': 460,\n",
       " 'nothing': 461,\n",
       " 'next': 462,\n",
       " 'instago': 463,\n",
       " 'loving': 464,\n",
       " 'early': 465,\n",
       " 'mom': 466,\n",
       " 'ready': 467,\n",
       " 'she': 468,\n",
       " 'haha': 469,\n",
       " 'saturday': 470,\n",
       " 'things': 471,\n",
       " 'broken': 472,\n",
       " 'monday': 473,\n",
       " 'show': 474,\n",
       " 'fresh': 475,\n",
       " 'tab': 476,\n",
       " 'swag': 477,\n",
       " 'while': 478,\n",
       " 'favorite': 479,\n",
       " 'v': 480,\n",
       " 'shit': 481,\n",
       " 'fast': 482,\n",
       " 'geek': 483,\n",
       " 'quote': 484,\n",
       " 'where': 485,\n",
       " 'business': 486,\n",
       " 'toy': 487,\n",
       " 'long': 488,\n",
       " 'being': 489,\n",
       " 'color': 490,\n",
       " 'joy': 491,\n",
       " 'pc': 492,\n",
       " 'jj': 493,\n",
       " 'his': 494,\n",
       " 'pay': 495,\n",
       " 'iphones': 496,\n",
       " 'peace': 497,\n",
       " 'piece': 498,\n",
       " 'dont': 499,\n",
       " 'husband': 500,\n",
       " 'perfect': 501,\n",
       " 'stuff': 502,\n",
       " 'anyone': 503,\n",
       " 'start': 504,\n",
       " 'india': 505,\n",
       " 'gadget': 506,\n",
       " 'charge': 507,\n",
       " 'real': 508,\n",
       " 'moment': 509,\n",
       " 'water': 510,\n",
       " 'many': 511,\n",
       " 'model': 512,\n",
       " 'gadgets': 513,\n",
       " 'gone': 514,\n",
       " 'someone': 515,\n",
       " 'enough': 516,\n",
       " 'tree': 517,\n",
       " 'ago': 518,\n",
       " 'same': 519,\n",
       " 'months': 520,\n",
       " 'college': 521,\n",
       " 'relax': 522,\n",
       " 'gratitude': 523,\n",
       " 'gay': 524,\n",
       " 'arrived': 525,\n",
       " 'phonecase': 526,\n",
       " 'care': 527,\n",
       " 'anything': 528,\n",
       " 'unlocked': 529,\n",
       " 'blessed': 530,\n",
       " 'yet': 531,\n",
       " 'steemit': 532,\n",
       " 'image': 533,\n",
       " 'light': 534,\n",
       " 'os': 535,\n",
       " 'reason': 536,\n",
       " 'sleep': 537,\n",
       " 'bad': 538,\n",
       " 'win': 539,\n",
       " 'code': 540,\n",
       " 'igdaily': 541,\n",
       " 'sonylens': 542,\n",
       " 'actually': 543,\n",
       " 'air': 544,\n",
       " 'kiss': 545,\n",
       " 'florida': 546,\n",
       " 'steve': 547,\n",
       " 'listen': 548,\n",
       " 'imessage': 549,\n",
       " 'pie': 550,\n",
       " 'stop': 551,\n",
       " 'turn': 552,\n",
       " 'instalike': 553,\n",
       " 'flower': 554,\n",
       " 'healthy': 555,\n",
       " 'ugh': 556,\n",
       " 'broke': 557,\n",
       " 'away': 558,\n",
       " 'hope': 559,\n",
       " 'problems': 560,\n",
       " 'sonyphotography': 561,\n",
       " 'sad': 562,\n",
       " 'song': 563,\n",
       " 'house': 564,\n",
       " 'images': 565,\n",
       " 'looks': 566,\n",
       " 'sync': 567,\n",
       " 'looking': 568,\n",
       " 'before': 569,\n",
       " 'xbox': 570,\n",
       " 'ok': 571,\n",
       " 'london': 572,\n",
       " 'instahub': 573,\n",
       " 'edge': 574,\n",
       " 'cable': 575,\n",
       " 'coffee': 576,\n",
       " 'used': 577,\n",
       " 'change': 578,\n",
       " 'feel': 579,\n",
       " 'italy': 580,\n",
       " 'kindle': 581,\n",
       " 'brand': 582,\n",
       " 'songs': 583,\n",
       " 'whole': 584,\n",
       " 'lg': 585,\n",
       " 'spring': 586,\n",
       " 'making': 587,\n",
       " 'uk': 588,\n",
       " 'maps': 589,\n",
       " 'dad': 590,\n",
       " 'school': 591,\n",
       " 'nyc': 592,\n",
       " 'pissed': 593,\n",
       " 'password': 594,\n",
       " 'galaxynote': 595,\n",
       " 'luxury': 596,\n",
       " 'wedding': 597,\n",
       " 'which': 598,\n",
       " 'company': 599,\n",
       " 'thailand': 600,\n",
       " 'single': 601,\n",
       " 'annoying': 602,\n",
       " 'imac': 603,\n",
       " 'fruit': 604,\n",
       " 'movies': 605,\n",
       " 'story': 606,\n",
       " 'contacts': 607,\n",
       " 'said': 608,\n",
       " 'device': 609,\n",
       " 'pm': 610,\n",
       " 'followsunday': 611,\n",
       " 'teamfollowback': 612,\n",
       " 'popular': 613,\n",
       " 'also': 614,\n",
       " 'rhymes': 615,\n",
       " 'rhyme': 616,\n",
       " 'version': 617,\n",
       " 'less': 618,\n",
       " 'h': 619,\n",
       " 'lock': 620,\n",
       " 'software': 621,\n",
       " 'chargers': 622,\n",
       " 'eyes': 623,\n",
       " 'unitedstate': 624,\n",
       " 'guitarplayer': 625,\n",
       " 'japan': 626,\n",
       " 'sonyphoto': 627,\n",
       " 'crap': 628,\n",
       " 'tomorrow': 629,\n",
       " 'order': 630,\n",
       " 'restore': 631,\n",
       " 'taken': 632,\n",
       " 'photofeed': 633,\n",
       " 'mirror': 634,\n",
       " 'ebay': 635,\n",
       " 'bestoftheday': 636,\n",
       " 'entrepreneur': 637,\n",
       " 'blackandwhite': 638,\n",
       " 'full': 639,\n",
       " 'without': 640,\n",
       " 'call': 641,\n",
       " 'car': 642,\n",
       " 'small': 643,\n",
       " 'worst': 644,\n",
       " 'tweet': 645,\n",
       " 'until': 646,\n",
       " 'ly': 647,\n",
       " 'break': 648,\n",
       " 'lifestyle': 649,\n",
       " 'icloud': 650,\n",
       " 'likes': 651,\n",
       " 'woman': 652,\n",
       " 'psn': 653,\n",
       " 'true': 654,\n",
       " 'something': 655,\n",
       " 'times': 656,\n",
       " 'own': 657,\n",
       " 'though': 658,\n",
       " 'delete': 659,\n",
       " 'run': 660,\n",
       " 'problem': 661,\n",
       " 'feeling': 662,\n",
       " 'saying': 663,\n",
       " 'holidays': 664,\n",
       " 'user': 665,\n",
       " 'sister': 666,\n",
       " 'htc': 667,\n",
       " 'numbers': 668,\n",
       " 'newyork': 669,\n",
       " 'portrait': 670,\n",
       " 'charging': 671,\n",
       " 'jun': 672,\n",
       " 'users': 673,\n",
       " 'him': 674,\n",
       " 'emoji': 675,\n",
       " 'decor': 676,\n",
       " 'minutes': 677,\n",
       " 'works': 678,\n",
       " 'canon': 679,\n",
       " 'smart': 680,\n",
       " 'messages': 681,\n",
       " 'usb': 682,\n",
       " 'vocation': 683,\n",
       " 'khaoko': 684,\n",
       " 'ilce': 685,\n",
       " 'email': 686,\n",
       " 'boyfriend': 687,\n",
       " 'words': 688,\n",
       " 'card': 689,\n",
       " 'button': 690,\n",
       " 'cant': 691,\n",
       " 'instacool': 692,\n",
       " 'features': 693,\n",
       " 'puppy': 694,\n",
       " 'giving': 695,\n",
       " 'click': 696,\n",
       " 'decided': 697,\n",
       " 'taking': 698,\n",
       " 'cellphone': 699,\n",
       " 'inch': 700,\n",
       " 'link': 701,\n",
       " 'sonya': 702,\n",
       " 'xmas': 703,\n",
       " 'else': 704,\n",
       " 'gets': 705,\n",
       " 'almost': 706,\n",
       " 'shotoniphone': 707,\n",
       " 'bit': 708,\n",
       " 'pcs': 709,\n",
       " 'foodporn': 710,\n",
       " 'flash': 711,\n",
       " 'applewatch': 712,\n",
       " 'through': 713,\n",
       " 'snapspeed': 714,\n",
       " 'photographer': 715,\n",
       " 'playing': 716,\n",
       " 'fit': 717,\n",
       " 'quotes': 718,\n",
       " 'pop': 719,\n",
       " 'offer': 720,\n",
       " 'sure': 721,\n",
       " 'wtf': 722,\n",
       " 'space': 723,\n",
       " 'tonight': 724,\n",
       " 'feed': 725,\n",
       " 'fixed': 726,\n",
       " 'month': 727,\n",
       " 'repair': 728,\n",
       " 'data': 729,\n",
       " 'updates': 730,\n",
       " 'city': 731,\n",
       " 'went': 732,\n",
       " 'different': 733,\n",
       " 'fml': 734,\n",
       " 'flowers': 735,\n",
       " 'super': 736,\n",
       " 'dj': 737,\n",
       " 'weeks': 738,\n",
       " 'thought': 739,\n",
       " 'wont': 740,\n",
       " 'garden': 741,\n",
       " 'reallyreal': 742,\n",
       " 'isn': 743,\n",
       " 'truth': 744,\n",
       " 'message': 745,\n",
       " 'those': 746,\n",
       " 'lens': 747,\n",
       " 'film': 748,\n",
       " 'set': 749,\n",
       " 'videos': 750,\n",
       " 'samsunggalaxys': 751,\n",
       " 'learn': 752,\n",
       " 'tell': 753,\n",
       " 'keyboard': 754,\n",
       " 'literally': 755,\n",
       " 'ootd': 756,\n",
       " 'wrong': 757,\n",
       " 'id': 758,\n",
       " 'ur': 759,\n",
       " 'ipadmini': 760,\n",
       " 'passion': 761,\n",
       " 'goes': 762,\n",
       " 'daily': 763,\n",
       " 'loves': 764,\n",
       " 'once': 765,\n",
       " 'fucked': 766,\n",
       " 'moments': 767,\n",
       " 'fitness': 768,\n",
       " 'throw': 769,\n",
       " 'daughter': 770,\n",
       " 'tmobile': 771,\n",
       " 'guy': 772,\n",
       " 'makeup': 773,\n",
       " 'forever': 774,\n",
       " 'might': 775,\n",
       " 'simple': 776,\n",
       " 'daddy': 777,\n",
       " 'sea': 778,\n",
       " 'april': 779,\n",
       " 'tuesday': 780,\n",
       " 'thankyou': 781,\n",
       " 'goodnight': 782,\n",
       " 'prophet': 783,\n",
       " 'sound': 784,\n",
       " 'nike': 785,\n",
       " 'drink': 786,\n",
       " 'ny': 787,\n",
       " 'fb': 788,\n",
       " 'pics': 789,\n",
       " 'iphonecase': 790,\n",
       " 'orange': 791,\n",
       " 'haven': 792,\n",
       " 'poem': 793,\n",
       " 'line': 794,\n",
       " 'future': 795,\n",
       " 'instalove': 796,\n",
       " 'silver': 797,\n",
       " 'likeforlike': 798,\n",
       " 'left': 799,\n",
       " 'sick': 800,\n",
       " 'smiles': 801,\n",
       " 'together': 802,\n",
       " 'itself': 803,\n",
       " 'exquisite': 804,\n",
       " 'squishy': 805,\n",
       " 'charm': 806,\n",
       " 'straps': 807,\n",
       " 'giveawaypic': 808,\n",
       " 'miami': 809,\n",
       " 'half': 810,\n",
       " 'completely': 811,\n",
       " 'believe': 812,\n",
       " 'dogs': 813,\n",
       " 'yesterday': 814,\n",
       " 'facetime': 815,\n",
       " 'cake': 816,\n",
       " 'photobooth': 817,\n",
       " 'dance': 818,\n",
       " 'rain': 819,\n",
       " 'porn': 820,\n",
       " 'post': 821,\n",
       " 'wife': 822,\n",
       " 'fan': 823,\n",
       " 'keeps': 824,\n",
       " 'were': 825,\n",
       " 'kid': 826,\n",
       " 'blackfriday': 827,\n",
       " 'visit': 828,\n",
       " 'computers': 829,\n",
       " 'mm': 830,\n",
       " 'shitty': 831,\n",
       " 'release': 832,\n",
       " 'lte': 833,\n",
       " 'indonesia': 834,\n",
       " 'tattoo': 835,\n",
       " 'lot': 836,\n",
       " 'totally': 837,\n",
       " 'men': 838,\n",
       " 'end': 839,\n",
       " 'proud': 840,\n",
       " 'fact': 841,\n",
       " 'least': 842,\n",
       " 'drop': 843,\n",
       " 'cracked': 844,\n",
       " 'latest': 845,\n",
       " 'bestfriend': 846,\n",
       " 'buying': 847,\n",
       " 'send': 848,\n",
       " 'snow': 849,\n",
       " 'zeeland': 850,\n",
       " 'account': 851,\n",
       " 'both': 852,\n",
       " 'xperiaz': 853,\n",
       " 'cause': 854,\n",
       " 'storage': 855,\n",
       " 'slow': 856,\n",
       " 'sent': 857,\n",
       " 'mother': 858,\n",
       " 'canada': 859,\n",
       " 'california': 860,\n",
       " 'deal': 861,\n",
       " 'price': 862,\n",
       " 'unique': 863,\n",
       " 'trump': 864,\n",
       " 'word': 865,\n",
       " 'rose': 866,\n",
       " 'relationships': 867,\n",
       " 'wireless': 868,\n",
       " 'upgraded': 869,\n",
       " 'sonyphotos': 870,\n",
       " 'sorority': 871,\n",
       " 'open': 872,\n",
       " 'gear': 873,\n",
       " 'sonyalpha': 874,\n",
       " 'read': 875,\n",
       " 'inlove': 876,\n",
       " 'uae': 877,\n",
       " 'needs': 878,\n",
       " 'stevejobs': 879,\n",
       " 'america': 880,\n",
       " 'yummy': 881,\n",
       " 'far': 882,\n",
       " 'march': 883,\n",
       " 'aliusaexpress': 884,\n",
       " 'fans': 885,\n",
       " 'shot': 886,\n",
       " 'ordered': 887,\n",
       " 'such': 888,\n",
       " 'january': 889,\n",
       " 'brother': 890,\n",
       " 'june': 891,\n",
       " 'devices': 892,\n",
       " 'artist': 893,\n",
       " 'hd': 894,\n",
       " 'gs': 895,\n",
       " 'purchase': 896,\n",
       " 'save': 897,\n",
       " 'king': 898,\n",
       " 'paris': 899,\n",
       " 'digital': 900,\n",
       " 'wall': 901,\n",
       " 'able': 902,\n",
       " 'three': 903,\n",
       " 'between': 904,\n",
       " 'sorry': 905,\n",
       " 'dead': 906,\n",
       " 'team': 907,\n",
       " 'purple': 908,\n",
       " 'boys': 909,\n",
       " 'mode': 910,\n",
       " 'shipping': 911,\n",
       " 'bots': 912,\n",
       " 'phonecases': 913,\n",
       " 'room': 914,\n",
       " 'touch': 915,\n",
       " 'office': 916,\n",
       " 'bday': 917,\n",
       " 'says': 918,\n",
       " 'reposting': 919,\n",
       " 'later': 920,\n",
       " 'clouds': 921,\n",
       " 'delicious': 922,\n",
       " 'yum': 923,\n",
       " 'november': 924,\n",
       " 'soul': 925,\n",
       " 'goodbye': 926,\n",
       " 'okay': 927,\n",
       " 'movie': 928,\n",
       " 'mind': 929,\n",
       " 'running': 930,\n",
       " 'magic': 931,\n",
       " 'console': 932,\n",
       " 'led': 933,\n",
       " 'drive': 934,\n",
       " 'sim': 935,\n",
       " 'street': 936,\n",
       " 'shoot': 937,\n",
       " 'photograph': 938,\n",
       " 'valentinesday': 939,\n",
       " 'chill': 940,\n",
       " 'cut': 941,\n",
       " 'moto': 942,\n",
       " 'type': 943,\n",
       " 'tired': 944,\n",
       " 'replace': 945,\n",
       " 'special': 946,\n",
       " 'texts': 947,\n",
       " 'breakfast': 948,\n",
       " 'yourself': 949,\n",
       " 'library': 950,\n",
       " 'talk': 951,\n",
       " 'europe': 952,\n",
       " 'sprint': 953,\n",
       " 'dropped': 954,\n",
       " 'droid': 955,\n",
       " 'few': 956,\n",
       " 'past': 957,\n",
       " 'market': 958,\n",
       " 'mi': 959,\n",
       " 'longer': 960,\n",
       " 'thx': 961,\n",
       " 'adorable': 962,\n",
       " 'chocolate': 963,\n",
       " 'view': 964,\n",
       " 'landscape': 965,\n",
       " 'hashtag': 966,\n",
       " 'fall': 967,\n",
       " 'hand': 968,\n",
       " 'replaced': 969,\n",
       " 'da': 970,\n",
       " 'bright': 971,\n",
       " 'creative': 972,\n",
       " 'singer': 973,\n",
       " 'evening': 974,\n",
       " 'glad': 975,\n",
       " 'rid': 976,\n",
       " 'chilling': 977,\n",
       " 'wouldn': 978,\n",
       " 'newtoy': 979,\n",
       " 'mad': 980,\n",
       " 'justinbieber': 981,\n",
       " 'smartphones': 982,\n",
       " 'purpose': 983,\n",
       " 'dinner': 984,\n",
       " 'spent': 985,\n",
       " 'samsungmobile': 986,\n",
       " 'vaio': 987,\n",
       " 'blonde': 988,\n",
       " 'unlock': 989,\n",
       " 'around': 990,\n",
       " 'dream': 991,\n",
       " 'angry': 992,\n",
       " 'xd': 993,\n",
       " 'winter': 994,\n",
       " 'subscribe': 995,\n",
       " 'complete': 996,\n",
       " 'load': 997,\n",
       " 'applesucks': 998,\n",
       " 'collection': 999,\n",
       " 'date': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15198"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences \n",
    "\n",
    "# maximum sequence length allowed\n",
    "max_len = 100\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq = x_tokenizer.texts_to_sequences(X_train) \n",
    "x_val_seq = x_tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "#padding up with zero \n",
    "x_tr_seq = pad_sequences(x_tr_seq,  padding='post', maxlen=max_len)\n",
    "x_val_seq = pad_sequences(x_val_seq, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  33, 1435,    4,   11,    1,  150,  175,   17,    1,    2,   37,\n",
       "       2148,   18,   87,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0], dtype=int32)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr_seq[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "#sequential model\n",
    "model = Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model.add(Embedding(len(x_tokenizer.word_index) + 1, 50, input_shape=(max_len,), mask_zero=True))\n",
    "\n",
    "#rnn layer\n",
    "model.add(SimpleRNN(128,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#dense layer\n",
    "model.add(Dense(128,activation='relu')) \n",
    "\n",
    "#output layer\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 50)           759950    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               22912     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 799,503\n",
      "Trainable params: 799,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer to adam and loss function to binary crossentropy. We will use f1 score as the metric\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[get_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint to save best model during training\n",
    "mc = ModelCheckpoint(\"../models/rnn_weights.best.hdf5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.4813 - get_f1: 0.0115\n",
      "Epoch 1: val_loss improved from inf to 0.34830, saving model to ../models/mlp_weights.best.hdf5\n",
      "50/50 [==============================] - 4s 61ms/step - loss: 0.4803 - get_f1: 0.0113 - val_loss: 0.3483 - val_get_f1: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2857 - get_f1: 0.4957\n",
      "Epoch 2: val_loss improved from 0.34830 to 0.31849, saving model to ../models/mlp_weights.best.hdf5\n",
      "50/50 [==============================] - 4s 80ms/step - loss: 0.2857 - get_f1: 0.4957 - val_loss: 0.3185 - val_get_f1: 0.7687\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1962 - get_f1: 0.8621\n",
      "Epoch 3: val_loss improved from 0.31849 to 0.27881, saving model to ../models/mlp_weights.best.hdf5\n",
      "50/50 [==============================] - 4s 81ms/step - loss: 0.1962 - get_f1: 0.8621 - val_loss: 0.2788 - val_get_f1: 0.8040\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1150 - get_f1: 0.9239\n",
      "Epoch 4: val_loss did not improve from 0.27881\n",
      "50/50 [==============================] - 4s 81ms/step - loss: 0.1150 - get_f1: 0.9239 - val_loss: 0.3193 - val_get_f1: 0.7913\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0684 - get_f1: 0.9547\n",
      "Epoch 5: val_loss did not improve from 0.27881\n",
      "50/50 [==============================] - 4s 85ms/step - loss: 0.0684 - get_f1: 0.9547 - val_loss: 0.4241 - val_get_f1: 0.7623\n",
      "Epoch 6/10\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0349 - get_f1: 0.9807\n",
      "Epoch 6: val_loss did not improve from 0.27881\n",
      "50/50 [==============================] - 4s 86ms/step - loss: 0.0353 - get_f1: 0.9801 - val_loss: 0.4218 - val_get_f1: 0.7553\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0232 - get_f1: 0.9855\n",
      "Epoch 7: val_loss did not improve from 0.27881\n",
      "50/50 [==============================] - 4s 78ms/step - loss: 0.0232 - get_f1: 0.9855 - val_loss: 0.5445 - val_get_f1: 0.7360\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0128 - get_f1: 0.9899\n",
      "Epoch 8: val_loss did not improve from 0.27881\n",
      "50/50 [==============================] - 4s 78ms/step - loss: 0.0128 - get_f1: 0.9899 - val_loss: 0.5985 - val_get_f1: 0.7452\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0137 - get_f1: 0.9930\n",
      "Epoch 9: val_loss did not improve from 0.27881\n",
      "50/50 [==============================] - 4s 83ms/step - loss: 0.0137 - get_f1: 0.9930 - val_loss: 0.7077 - val_get_f1: 0.7080\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0179 - get_f1: 0.9905\n",
      "Epoch 10: val_loss did not improve from 0.27881\n",
      "50/50 [==============================] - 4s 81ms/step - loss: 0.0179 - get_f1: 0.9905 - val_loss: 0.7929 - val_get_f1: 0.7470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99efb1c6d0>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model \n",
    "model.fit(x_tr_seq, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(x_val_seq, y_val), callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# load weights into new model\n",
    "model.load_weights(\"../models/rnn_weights.best.hdf5\")\n",
    "\n",
    "#predict probabilities\n",
    "pred_prob = model.predict(x_val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96341085], dtype=float32)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
       "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
       "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define candidate threshold values\n",
    "threshold  = np.arange(0,0.5,0.01)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert probabilities into classes or tags based on a threshold value\n",
    "def classify(pred_prob,thresh):\n",
    "  y_pred_seq = []\n",
    "\n",
    "  for i in pred_prob:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "      if j>=thresh:\n",
    "        temp.append(1)\n",
    "      else:\n",
    "        temp.append(0)\n",
    "    y_pred_seq.append(temp)\n",
    "\n",
    "  return y_pred_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "score=[]\n",
    "\n",
    "#convert to 1 array\n",
    "y_true = np.array(y_val).ravel() \n",
    "\n",
    "for thresh in threshold:\n",
    "    \n",
    "    #classes for each threshold\n",
    "    y_pred_seq = classify(pred_prob,thresh) \n",
    "\n",
    "    #convert to 1d array\n",
    "    y_pred = np.array(y_pred_seq).ravel()\n",
    "\n",
    "    score.append(metrics.f1_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41000000000000003"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the optimal threshold\n",
    "opt = threshold[score.index(max(score))]\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for optimal threshold\n",
    "y_pred_seq = classify(pred_prob,opt)\n",
    "y_pred = np.array(y_pred_seq).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      1179\n",
      "           1       0.73      0.89      0.80       405\n",
      "\n",
      "    accuracy                           0.89      1584\n",
      "   macro avg       0.85      0.89      0.86      1584\n",
      "weighted avg       0.90      0.89      0.89      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>actual</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>my iphone  it sucks  keeps screwing up  shut off  freezes  and all that jazz</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>flower art  flower  art  colour  photography  creative  beautiful  lines  samsung  tuesday pic twitter com  xd uwxqnq</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>got my  ps  with a copy of killzone shadow fall and a year of ps plus   sony  ps   killzone</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>coffee is love    iphoneography  instagram  iphonesia  photooftheday  iphone  instagood  popular</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>i m sure my iphone just deleted every text message in the history of all my contacts   apple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    comment  \\\n",
       "906                                           my iphone  it sucks  keeps screwing up  shut off  freezes  and all that jazz    \n",
       "3556  flower art  flower  art  colour  photography  creative  beautiful  lines  samsung  tuesday pic twitter com  xd uwxqnq   \n",
       "2043                          got my  ps  with a copy of killzone shadow fall and a year of ps plus   sony  ps   killzone     \n",
       "1264                    coffee is love    iphoneography  instagram  iphonesia  photooftheday  iphone  instagood  popular      \n",
       "5337                           i m sure my iphone just deleted every text message in the history of all my contacts   apple   \n",
       "\n",
       "      actual  predictions  \n",
       "906        1            1  \n",
       "3556       0            0  \n",
       "2043       0            1  \n",
       "1264       0            0  \n",
       "5337       0            1  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'comment':X_val,'actual':y_true,'predictions':y_pred})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer\n",
    "x_tokenizer = Tokenizer() \n",
    "\n",
    "X_test = df_test[\"clean_tweet\"]\n",
    "\n",
    "x_tokenizer.fit_on_texts(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6889"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences \n",
    "\n",
    "# maximum sequence length allowed\n",
    "max_len = 100\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_test_seq = x_tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "#padding up with zero \n",
    "x_test_seq = pad_sequences(x_test_seq,  padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1491, 1492,    4,  116, 1493,    2,  424, 2353, 2354, 2355,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0], dtype=int32)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_seq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "#predict probabilities\n",
    "pred_test_prob = model.predict(x_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for optimal threshold\n",
    "y_pred_test_seq = classify(pred_test_prob,opt)\n",
    "y_pred_test = np.array(y_pred_test_seq).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[\"label\"] = y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  label\n",
       "0  7921      1\n",
       "1  7922      0\n",
       "2  7923      1\n",
       "3  7924      0\n",
       "4  7925      0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"../results/submission_rnn_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 50)           759950    \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 100, 50)          0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 100, 64)           16064     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              66048     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 866,895\n",
      "Trainable params: 866,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model architecture\n",
    "K.clear_session()\n",
    "model =  Sequential()\n",
    "model.add(Embedding(len(x_tokenizer.word_index) + 1, 50, trainable=True, input_shape=(max_len,)))  #embedding layer\n",
    "\n",
    "model.add(SpatialDropout1D(0.2)) #spatialdropout1d layer\n",
    "\n",
    "model.add(Conv1D(64,5,padding='same', activation='relu'))  #conv1d layer\n",
    "model.add(Bidirectional(LSTM(64,dropout=0.2, recurrent_dropout=0.2))) #bidirectional lstm layer\n",
    "model.add(Dense(128,activation='relu'))  #dense layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64,activation='relu')) #dense layer\n",
    "\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid')) #output layer\n",
    "model.summary() #summary) of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimizer and loss\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=[get_f1])\n",
    "\n",
    "#checkpoint to save best model during training\n",
    "mc = ModelCheckpoint(\"../models/cnn.weights.best.hdf5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5281 - get_f1: 0.0837\n",
      "Epoch 1: val_loss improved from inf to 0.37332, saving model to ../models/cnn.weights.best.hdf5\n",
      "50/50 [==============================] - 13s 166ms/step - loss: 0.5281 - get_f1: 0.0837 - val_loss: 0.3733 - val_get_f1: 0.6130\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2447 - get_f1: 0.8024\n",
      "Epoch 2: val_loss improved from 0.37332 to 0.25281, saving model to ../models/cnn.weights.best.hdf5\n",
      "50/50 [==============================] - 11s 224ms/step - loss: 0.2447 - get_f1: 0.8024 - val_loss: 0.2528 - val_get_f1: 0.8028\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1439 - get_f1: 0.8913\n",
      "Epoch 3: val_loss did not improve from 0.25281\n",
      "50/50 [==============================] - 10s 210ms/step - loss: 0.1439 - get_f1: 0.8913 - val_loss: 0.2869 - val_get_f1: 0.7843\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0839 - get_f1: 0.9422\n",
      "Epoch 4: val_loss did not improve from 0.25281\n",
      "50/50 [==============================] - 10s 193ms/step - loss: 0.0839 - get_f1: 0.9422 - val_loss: 0.3509 - val_get_f1: 0.7624\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0560 - get_f1: 0.9673\n",
      "Epoch 5: val_loss did not improve from 0.25281\n",
      "50/50 [==============================] - 10s 194ms/step - loss: 0.0560 - get_f1: 0.9673 - val_loss: 0.3851 - val_get_f1: 0.7693\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0306 - get_f1: 0.9830\n",
      "Epoch 6: val_loss did not improve from 0.25281\n",
      "50/50 [==============================] - 10s 199ms/step - loss: 0.0306 - get_f1: 0.9830 - val_loss: 0.4903 - val_get_f1: 0.7605\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0222 - get_f1: 0.9877\n",
      "Epoch 7: val_loss did not improve from 0.25281\n",
      "50/50 [==============================] - 10s 198ms/step - loss: 0.0222 - get_f1: 0.9877 - val_loss: 0.5495 - val_get_f1: 0.7756\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0158 - get_f1: 0.9917\n",
      "Epoch 8: val_loss did not improve from 0.25281\n",
      "50/50 [==============================] - 9s 189ms/step - loss: 0.0158 - get_f1: 0.9917 - val_loss: 0.5980 - val_get_f1: 0.7573\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0162 - get_f1: 0.9892\n",
      "Epoch 9: val_loss did not improve from 0.25281\n",
      "50/50 [==============================] - 10s 195ms/step - loss: 0.0162 - get_f1: 0.9892 - val_loss: 0.6165 - val_get_f1: 0.7599\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0104 - get_f1: 0.9931\n",
      "Epoch 10: val_loss did not improve from 0.25281\n",
      "50/50 [==============================] - 9s 188ms/step - loss: 0.0104 - get_f1: 0.9931 - val_loss: 0.7217 - val_get_f1: 0.7513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99d628be50>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model \n",
    "model.fit(x_tr_seq, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(x_val_seq, y_val), callbacks=[mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 128)          1945472   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,093,697\n",
      "Trainable params: 2,093,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "K.clear_session()\n",
    "model =  Sequential()\n",
    "model.add(Embedding(len(x_tokenizer.word_index) + 1, 128, trainable=True, input_shape=(max_len,), mask_zero=True))  #embedding layer\n",
    "  \n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, input_shape =(1,)))\n",
    "\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "# Dense layer\n",
    "model.add(Dense(128,activation='relu')) \n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1,activation='sigmoid')) #output layer\n",
    "model.summary() #summary) of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimizer and loss\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=[get_f1])\n",
    "\n",
    "#checkpoint to save best model during training\n",
    "mc = ModelCheckpoint(\"../models/lstm.weights.best.hdf5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - ETA: 0s - loss: 0.0111 - get_f1: 0.9918\n",
      "Epoch 1: val_loss did not improve from 0.24433\n",
      "99/99 [==============================] - 18s 178ms/step - loss: 0.0111 - get_f1: 0.9918 - val_loss: 0.7542 - val_get_f1: 0.7240\n",
      "Epoch 2/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0196 - get_f1: 0.9882\n",
      "Epoch 2: val_loss did not improve from 0.24433\n",
      "99/99 [==============================] - 19s 190ms/step - loss: 0.0196 - get_f1: 0.9882 - val_loss: 0.7857 - val_get_f1: 0.7114\n",
      "Epoch 3/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0207 - get_f1: 0.9872\n",
      "Epoch 3: val_loss did not improve from 0.24433\n",
      "99/99 [==============================] - 18s 184ms/step - loss: 0.0207 - get_f1: 0.9872 - val_loss: 0.7480 - val_get_f1: 0.7262\n",
      "Epoch 4/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0066 - get_f1: 0.9969\n",
      "Epoch 4: val_loss did not improve from 0.24433\n",
      "99/99 [==============================] - 17s 171ms/step - loss: 0.0066 - get_f1: 0.9969 - val_loss: 0.7952 - val_get_f1: 0.7387\n",
      "Epoch 5/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0068 - get_f1: 0.9967\n",
      "Epoch 5: val_loss did not improve from 0.24433\n",
      "99/99 [==============================] - 17s 169ms/step - loss: 0.0068 - get_f1: 0.9967 - val_loss: 0.9803 - val_get_f1: 0.7074\n",
      "Epoch 6/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0075 - get_f1: 0.9951\n",
      "Epoch 6: val_loss did not improve from 0.24433\n",
      "99/99 [==============================] - 16s 165ms/step - loss: 0.0075 - get_f1: 0.9951 - val_loss: 0.9263 - val_get_f1: 0.6946\n",
      "Epoch 7/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0082 - get_f1: 0.9945\n",
      "Epoch 7: val_loss did not improve from 0.24433\n",
      "99/99 [==============================] - 17s 168ms/step - loss: 0.0082 - get_f1: 0.9945 - val_loss: 0.7850 - val_get_f1: 0.7300\n",
      "Epoch 8/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0055 - get_f1: 0.9970\n",
      "Epoch 8: val_loss did not improve from 0.24433\n",
      "99/99 [==============================] - 18s 179ms/step - loss: 0.0055 - get_f1: 0.9970 - val_loss: 0.8552 - val_get_f1: 0.7024\n",
      "Epoch 9/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0049 - get_f1: 0.9966\n",
      "Epoch 9: val_loss did not improve from 0.24433\n",
      "99/99 [==============================] - 16s 162ms/step - loss: 0.0049 - get_f1: 0.9966 - val_loss: 1.0396 - val_get_f1: 0.7217\n",
      "Epoch 10/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0037 - get_f1: 0.9984\n",
      "Epoch 10: val_loss did not improve from 0.24433\n",
      "99/99 [==============================] - 16s 163ms/step - loss: 0.0037 - get_f1: 0.9984 - val_loss: 1.1297 - val_get_f1: 0.7347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99ecedcd00>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model \n",
    "model.fit(x_tr_seq, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(x_val_seq, y_val), callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
